{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644fc36b",
   "metadata": {},
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8598e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from rapidfireai.infer.experiment import Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025bbf90",
   "metadata": {},
   "source": [
    "### Model config and Sampling Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623742da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62fa27a",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa87f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test split for evaluation (not train)\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "print(f\"Loaded {len(dataset)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a21ee",
   "metadata": {},
   "source": [
    "### RAG Implementation using `LangChainRagSpec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b73586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from rapidfireai.infer.rag.context_generator import ContextGenerator\n",
    "from rapidfireai.infer.rag.rag_pipeline import LangChainRagSpec\n",
    "from rapidfireai.infer.utils.config import VLLMModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bab18b",
   "metadata": {},
   "source": [
    "#### CPU RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cpu = LangChainRagSpec(\n",
    "    document_loader=DirectoryLoader(\n",
    "        path=\"../data/gsm8k\",\n",
    "        glob=\"*.txt\",\n",
    "        recursive=True,\n",
    "        sample_seed=1337\n",
    "    ),\n",
    "    text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        encoding_name=\"gpt2\", chunk_size=128, chunk_overlap=32\n",
    "    ),\n",
    "    embedding_cls=HuggingFaceEmbeddings,\n",
    "    embedding_kwargs={\n",
    "        'model_name': \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        'model_kwargs': {'device': 'cpu'},\n",
    "        'encode_kwargs': {'normalize_embeddings': True, 'batch_size': batch_size}\n",
    "    },\n",
    "    retriever=None,\n",
    "    vector_store=None, # Uses FAISS CPU with HNSW approximate nearest neighbor search\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    "    reranker=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0349b5b",
   "metadata": {},
   "source": [
    "#### GPU RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_gpu = LangChainRagSpec(\n",
    "    document_loader=DirectoryLoader(\n",
    "        path=\"../data/gsm8k\",\n",
    "        glob=\"*.txt\",\n",
    "        recursive=True,\n",
    "        sample_seed=1337\n",
    "    ),\n",
    "    text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        encoding_name=\"gpt2\", chunk_size=128, chunk_overlap=32\n",
    "    ),\n",
    "    embedding_cls=HuggingFaceEmbeddings,\n",
    "    embedding_kwargs={\n",
    "        'model_name': \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        'model_kwargs': {'device': 'cuda:0'},\n",
    "        'encode_kwargs': {'normalize_embeddings': True, 'batch_size': batch_size}\n",
    "    },\n",
    "    retriever=None,\n",
    "    vector_store=None, # Uses FAISS GPU with indexed exact search when `enable_gpu_search=True` is set\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    "    reranker=None,\n",
    "    enable_gpu_search=True # Search computation is performed on GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ContextGenerators wrapping RAG specs\n",
    "context_generator_cpu = ContextGenerator(rag_spec=rag_cpu)\n",
    "context_generator_gpu = ContextGenerator(rag_spec=rag_gpu)\n",
    "\n",
    "model_config={\n",
    "    \"model\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    \"dtype\": \"half\",\n",
    "    \"gpu_memory_utilization\": 0.7,\n",
    "    \"tensor_parallel_size\": 1,\n",
    "    \"distributed_executor_backend\": \"mp\",\n",
    "    \"enable_chunked_prefill\": True,\n",
    "    \"enable_prefix_caching\": True,\n",
    "    \"max_model_len\": 2048,\n",
    "    \"disable_log_stats\": True,  # Disable VLLM progress logging\n",
    "}\n",
    "sampling_params={\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"max_tokens\": 512,\n",
    "}\n",
    "\n",
    "pipeline_cpu = VLLMModelConfig(\n",
    "    model_config=model_config,\n",
    "    sampling_params=sampling_params,\n",
    "    context_generator=context_generator_cpu\n",
    ")\n",
    "\n",
    "pipeline_gpu = VLLMModelConfig(\n",
    "    model_config=model_config,\n",
    "    sampling_params=sampling_params,\n",
    "    context_generator=context_generator_gpu\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb16c3",
   "metadata": {},
   "source": [
    "### Utility, Preprocessor, Postprocessor, Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22773d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_solution(answer):\n",
    "    solution = re.search(\"#### (\\\\-?[0-9\\\\.\\\\,]+)\", answer)\n",
    "    if solution is None:\n",
    "        return \"0\"\n",
    "    final_solution = solution.group(0)\n",
    "    final_solution = final_solution.split(\"#### \")[1].replace(\",\", \"\")\n",
    "    return final_solution\n",
    "\n",
    "def preprocess_fn(batch: Dict[str, List], context_generator: ContextGenerator) -> Dict[str, List]:\n",
    "    return {\n",
    "        \"prompts\": [\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": 'Let\\'s think step by step and output the final answer after \"####\".'\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f'{question}. You can use the following context to answer the question:\\n{context}'\n",
    "                }\n",
    "            ]\n",
    "            for question, context in zip(batch[\"question\"], context_generator.get_context(batch[\"question\"]))\n",
    "        ],\n",
    "        **batch,\n",
    "    }\n",
    "\n",
    "def postprocess_fn(batch: Dict[str, List]) -> Dict[str, List]:\n",
    "    batch[\"model_answer\"] = [extract_solution(answer) for answer in batch[\"generated_text\"]]\n",
    "    batch[\"ground_truth\"] = [extract_solution(answer) for answer in batch[\"answer\"]]\n",
    "    return batch\n",
    "\n",
    "def compute_metrics_fn(batch: Dict[str, List]) -> Dict[str, Dict[str, Any]]:\n",
    "    correct = sum(1 for pred, gt in zip(batch[\"model_answer\"], batch[\"ground_truth\"])\n",
    "                  if pred == gt)\n",
    "    total = len(batch[\"model_answer\"])\n",
    "    return {\n",
    "        \"Correct\": {\"value\": correct},\n",
    "        \"Total\": {\"value\": total},\n",
    "    }\n",
    "\n",
    "def accumulate_metrics_fn(aggregated_metrics: Dict[str, List]) -> Dict[str, Dict[str, Any]]:\n",
    "    # aggregated_metrics is a dict of lists: {\"Correct\": [5, 3, 7], \"Total\": [10, 8, 12]}\n",
    "    correct = sum(m.get(\"value\", 0) for m in aggregated_metrics.get(\"Correct\", [{}]))\n",
    "    total = sum(m.get(\"value\", 0) for m in aggregated_metrics.get(\"Total\", [{}]))\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return {\n",
    "        \"Total\": {\"value\": total},\n",
    "        \"Correct\": {\"value\": correct, \"is_distributive\": True, \"value_range\": (0, 1)}, # 0 (min) if not correct, 1 if correct (max)\n",
    "        \"Accuracy\": {\"value\": accuracy, \"is_algebraic\": True, \"value_range\": (0, 1)} # Algebraic metric for online aggregation\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4699f9",
   "metadata": {},
   "source": [
    "### Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(experiment_name=\"trial-rag-langchain\", num_actors=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa186134",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b0d70",
   "metadata": {},
   "source": [
    "#### CPU based execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results, metrics = experiment.run_evals(\n",
    "    pipeline_cpu,\n",
    "    dataset,\n",
    "    batch_size=batch_size,  # Per actor batch size\n",
    "    preprocess_fn=preprocess_fn,\n",
    "    postprocess_fn=postprocess_fn,\n",
    "    compute_metrics_fn=compute_metrics_fn,\n",
    "    accumulate_metrics_fn=accumulate_metrics_fn,\n",
    "    online_strategy_kwargs={\"strategy_name\": \"normal\", \"confidence_level\": 0.95, \"use_fpc\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c471a",
   "metadata": {},
   "source": [
    "#### GPU based execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa82909",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results, metrics = experiment.run_evals(\n",
    "    pipeline_gpu,\n",
    "    dataset,\n",
    "    batch_size=batch_size,  # Per actor batch size\n",
    "    preprocess_fn=preprocess_fn,\n",
    "    postprocess_fn=postprocess_fn,\n",
    "    compute_metrics_fn=compute_metrics_fn,\n",
    "    accumulate_metrics_fn=accumulate_metrics_fn,\n",
    "    online_strategy_kwargs={\"strategy_name\": \"normal\", \"confidence_level\": 0.95, \"use_fpc\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135d951",
   "metadata": {},
   "source": [
    "### End Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ce33b",
   "metadata": {},
   "source": [
    "### View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756344e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nResults:\")\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70272fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFirst few examples:\")\n",
    "for i in range(min(3, metrics['Samples Processed']['value'])):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    prompt = aggregated_results['prompts'][i]\n",
    "    print(f\"System: \\n{prompt[0]['content']}\")\n",
    "    print(f\"User + Context: \\n{prompt[1]['content']}\")\n",
    "    print(f\"Model: \\n{aggregated_results['generated_text'][i]}\")\n",
    "    print(f\"Ground truth: \\n{aggregated_results['ground_truth'][i]}\")\n",
    "    print(f\"Model answer: \\n{aggregated_results['model_answer'][i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
